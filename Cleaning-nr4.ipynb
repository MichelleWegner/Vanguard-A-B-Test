{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully merged and saved in: ../Raw Data/df_combined.txt\n"
     ]
    }
   ],
   "source": [
    "# Reading Digital Footprints data\n",
    "file_path_1 = '../Raw Data/df_final_web_data_pt_1.txt'\n",
    "file_path_2 = '../Raw Data/df_final_web_data_pt_2.txt'\n",
    "file_path_demo = '../Raw Data/df_final_demo.txt'\n",
    "file_path_experiment = '../Raw Data/df_final_experiment_clients.txt'\n",
    "\n",
    "df_final_demo = pd.read_csv(file_path_demo, sep=\",\")\n",
    "df_final_experiment_clients = pd.read_csv(file_path_experiment, sep=\",\")\n",
    "\n",
    "df1 = pd.read_csv(file_path_1, sep=\",\")\n",
    "df2 = pd.read_csv(file_path_2, sep=',')\n",
    "\n",
    "# Combining Digital Footprints data\n",
    "df_combined = pd.concat([df1, df2])\n",
    "\n",
    "# Saving combined data\n",
    "output_path = '../Raw Data/df_combined.txt'\n",
    "df_combined.to_csv(output_path, sep=',', index=False)\n",
    "print(\"Data successfully merged and saved in:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataset's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id  clnt_tenure_yr  clnt_tenure_mnth  clnt_age gendr  num_accts  \\\n",
      "0     836976             6.0              73.0      60.5     U        2.0   \n",
      "1     836976             6.0              73.0      60.5     U        2.0   \n",
      "2     836976             6.0              73.0      60.5     U        2.0   \n",
      "3     836976             6.0              73.0      60.5     U        2.0   \n",
      "4     836976             6.0              73.0      60.5     U        2.0   \n",
      "\n",
      "       bal  calls_6_mnth  logons_6_mnth variation            visitor_id  \\\n",
      "0  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
      "1  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
      "2  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
      "3  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
      "4  45105.3           6.0            9.0      Test  427070339_1413275162   \n",
      "\n",
      "                      visit_id process_step            date_time  \n",
      "0  228976764_46825473280_96584      confirm  2017-04-02 11:51:13  \n",
      "1  228976764_46825473280_96584      confirm  2017-04-02 11:47:50  \n",
      "2  228976764_46825473280_96584      confirm  2017-04-02 11:46:45  \n",
      "3  228976764_46825473280_96584       step_3  2017-04-02 11:23:08  \n",
      "4  228976764_46825473280_96584       step_2  2017-04-02 11:22:24  \n"
     ]
    }
   ],
   "source": [
    "# Standardizing the column names\n",
    "df_final_demo.columns = df_final_demo.columns.str.strip().str.lower()\n",
    "df_final_experiment_clients.columns = df_final_experiment_clients.columns.str.strip().str.lower()\n",
    "df_combined.columns = df_combined.columns.str.strip().str.lower()\n",
    "\n",
    "# Merging the dataframes\n",
    "merged_df = pd.merge(df_final_demo, df_final_experiment_clients, on='client_id', how='inner')\n",
    "merged_df = pd.merge(merged_df, df_combined, on='client_id', how='inner')\n",
    "\n",
    "# Check the merged dataframe\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "Merge all datasets into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id           0\n",
      "clnt_tenure_yr      0\n",
      "clnt_tenure_mnth    0\n",
      "clnt_age            0\n",
      "gendr               0\n",
      "num_accts           0\n",
      "bal                 0\n",
      "calls_6_mnth        0\n",
      "logons_6_mnth       0\n",
      "variation           0\n",
      "visitor_id          0\n",
      "visit_id            0\n",
      "process_step        0\n",
      "date_time           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "Clean_Data = merged_df.dropna()\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(Clean_Data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Remove rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "Clean_Data = Clean_Data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Duplicates\n",
    "Remove any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "Clean_Data = Clean_Data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency in Data Types\n",
    "Ensure numerical and categorical data types are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numerical columns to appropriate data types\n",
    "numerical_columns = ['clnt_age', 'num_accts', 'bal', 'calls_6_mnth', 'logons_6_mnth']\n",
    "Clean_Data[numerical_columns] = Clean_Data[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Ensure 'gendr' is treated as a category\n",
    "Clean_Data['gendr'] = Clean_Data['gendr'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation\n",
    "\n",
    "Identify and remove outliers in numerical columns, especially 'bal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores for 'bal'\n",
    "Clean_Data['bal_zscore'] = zscore(Clean_Data['bal'])\n",
    "\n",
    "# Filter out outliers (those with z-score < -3 or > 3)\n",
    "Clean_Data_no_outliers = Clean_Data[(Clean_Data['bal_zscore'] >= -3) & (Clean_Data['bal_zscore'] <= 3)]\n",
    "\n",
    "# Drop the z-score column as it was only needed for outlier detection\n",
    "Clean_Data_no_outliers = Clean_Data_no_outliers.drop(columns=['bal_zscore'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean 'gendr' Column\n",
    "Remove rows where 'gendr' is 'U' or 'X', and drop NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'F']\n",
      "Categories (4, object): ['F', 'M', 'U', 'X']\n"
     ]
    }
   ],
   "source": [
    "# Filter out 'U' and 'X' from 'gendr' and drop NaN values\n",
    "Clean_Data_no_outliers = Clean_Data_no_outliers[Clean_Data_no_outliers['gendr'].isin(['M', 'F'])].dropna(subset=['gendr'])\n",
    "\n",
    "# Check unique values in 'gendr' to confirm cleaning\n",
    "print(Clean_Data_no_outliers['gendr'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleanup and Save\n",
    "Ensure the dataset is fully cleaned and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id           0\n",
      "clnt_tenure_yr      0\n",
      "clnt_tenure_mnth    0\n",
      "clnt_age            0\n",
      "gendr               0\n",
      "num_accts           0\n",
      "bal                 0\n",
      "calls_6_mnth        0\n",
      "logons_6_mnth       0\n",
      "variation           0\n",
      "visitor_id          0\n",
      "visit_id            0\n",
      "process_step        0\n",
      "date_time           0\n",
      "dtype: int64\n",
      "client_id              int64\n",
      "clnt_tenure_yr       float64\n",
      "clnt_tenure_mnth     float64\n",
      "clnt_age             float64\n",
      "gendr               category\n",
      "num_accts            float64\n",
      "bal                  float64\n",
      "calls_6_mnth         float64\n",
      "logons_6_mnth        float64\n",
      "variation             object\n",
      "visitor_id            object\n",
      "visit_id              object\n",
      "process_step          object\n",
      "date_time             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Final check for missing values and datatypes\n",
    "print(Clean_Data_no_outliers.isnull().sum())\n",
    "print(Clean_Data_no_outliers.dtypes)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "Clean_Data_no_outliers.to_csv('Clean_Data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 317123\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_cols = Clean_Data.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***client_id:*** A unique identifier for each client.\n",
    "***clnt_tenure_yr:*** The duration of the client's membership with Vanguard in years.\n",
    "***clnt_tenure_mnth:*** The duration of the client's membership with Vanguard in months.\n",
    "***clnt_age:*** The age of the customer.\n",
    "***gendr:*** The gender of the customer, with possible values being “M” (male), “F” (female), “U” (unknown), or “X” (unspecified).\n",
    "***num_accts:*** The number of accounts the customer has with Vanguard.\n",
    "***bal:*** The total balance across all of the customer's accounts.\n",
    "***calls_6_mnth:*** The number of calls the customer has made to customer service in the last six months.\n",
    "***logons_6_mnth:*** The number of times the customer has logged on to the Vanguard platform in the last six months.\n",
    "***variation:*** The group assignment for the A/B test (either “Control” or “Test”).\n",
    "***visitor_id:*** A unique identifier for each customer-device combination.\n",
    "***visit_id:*** A unique identifier for each visit/session on the website.\n",
    "***process_step:***The step in the digital process that the customer is in (e.g., “step_1”, “step_2”, “step_3”, or “confirm”).\n",
    "***date_time:*** The timestamp of when the customer performed a specific action on the website. ich meinte so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
